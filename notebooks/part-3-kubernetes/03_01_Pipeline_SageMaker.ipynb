{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist classification pipeline using Sagemaker\n",
    "\n",
    "The `mnist-classification-pipeline.py` sample runs a pipeline to train a classficiation model using Kmeans with MNIST dataset on Sagemaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have all required steps here and for other details like how to get source data, please check [documentation](https://github.com/kubeflow/pipelines/tree/master/samples/contrib/aws-samples/mnist-kmeans-sagemaker).\n",
    "\n",
    "\n",
    "This sample is based on the [Train a Model with a Built-in Algorithm and Deploy it](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1.html).\n",
    "\n",
    "The sample trains and deploy a model based on the [MNIST dataset](http://www.deeplearning.net/tutorial/gettingstarted.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy `data` and `valid_data.csv` into your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (1.11.8)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.8 in /opt/conda/lib/python3.6/site-packages (from boto3) (1.14.8)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3) (0.3.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.8->boto3) (0.15.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /opt/conda/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.8->boto3) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.8->boto3) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.8->boto3) (1.11.0)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-west-2-173153674984\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "AWS_ACCOUNT_ID = boto3.client('sts').get_caller_identity().get('Account')\n",
    "AWS_REGION = 'us-west-2'\n",
    "\n",
    "S3_BUCKET = 'sagemaker-{}-{}'.format(AWS_REGION, AWS_ACCOUNT_ID)\n",
    "print(S3_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://kubeflow-pipeline-data/mnist_kmeans_example/data to s3://sagemaker-us-west-2-173153674984/mnist_kmeans_example/data\n",
      "copy: s3://kubeflow-pipeline-data/mnist_kmeans_example/input/valid_data.csv to s3://sagemaker-us-west-2-173153674984/mnist_kmeans_example/input/valid_data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://kubeflow-pipeline-data/mnist_kmeans_example/data s3://$S3_BUCKET/mnist_kmeans_example/data\n",
    "\n",
    "!aws s3 cp s3://kubeflow-pipeline-data/mnist_kmeans_example/input/valid_data.csv s3://$S3_BUCKET/mnist_kmeans_example/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Kubeflow Pipelines SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://storage.googleapis.com/ml-pipeline/release/0.1.29/kfp.tar.gz\n",
      "\u001b[?25l  Downloading https://storage.googleapis.com/ml-pipeline/release/0.1.29/kfp.tar.gz (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 2.5MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3<1.25,>=1.15 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (5.2)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.25.0)\n",
      "Collecting kubernetes<=9.0.0,>=8.0.0 (from kfp==0.1.29)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/f7/4f196c55f1c2713d3edc8252c4b45326306eef4dc10048f13916fe446e2b/kubernetes-9.0.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 25.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: PyJWT>=1.6.4 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.6.4)\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.4.2 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: requests_toolbelt>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.2.2)\n",
      "Collecting kfp-server-api<=0.1.25,>=0.1.18 (from kfp==0.1.29)\n",
      "  Downloading https://files.pythonhosted.org/packages/3e/24/a82ae81487bf61fb262e67167cee1843f2f70d940713c092b124c9aaa0dc/kfp-server-api-0.1.18.3.tar.gz\n",
      "Collecting argo-models==2.2.1a (from kfp==0.1.29)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/53/a92df7c1c793edf2db99b14e428246e4b49b93499a5c9ed013e0aa2416f6/argo-models-2.2.1a0.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (3.2.0)\n",
      "Collecting tabulate==0.8.3 (from kfp==0.1.29)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 33.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: click==7.0 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (7.0)\n",
      "Collecting Deprecated (from kfp==0.1.29)\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.2.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp==0.1.29) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<0.6dev,>=0.5.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp==0.1.29) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (45.2.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp==0.1.29) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: idna>=2.1 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp==0.1.29) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.7 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp==0.1.29) (1.11.5)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp==0.1.29) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp==0.1.29) (3.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp==0.1.29) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp==0.1.29) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp==0.1.29) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp==0.1.29) (0.15.7)\n",
      "Collecting wrapt<2,>=1.10 (from Deprecated->kfp==0.1.29)\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/bc/7993faa8084b5a5dbabb07a197ae1b7590da4752dc80455d878573553e2f/wrapt-1.12.0.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.16.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==0.1.29) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib->kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.7->cryptography>=2.4.2->kfp==0.1.29) (2.18)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa<4.1,>=3.1.4->google-auth>=1.6.1->kfp==0.1.29) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp==0.1.29) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==0.1.29) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==0.1.29) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==0.1.29) (3.11.2)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp==0.1.29) (8.1.0)\n",
      "Building wheels for collected packages: kfp, kfp-server-api, argo-models, tabulate, wrapt\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-5vwjukbk/wheels/81/b7/33/00ef9dd992b13add014c4875a2c130d9d70288127a793c4af6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/07/13/f3/31e9e1a25e10b8c3d04df74a01f4dbcf16a4119272cd41ba7a\n",
      "  Building wheel for argo-models (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/bd/5b/6b/20cdc06ddb10caa3a86f5804eb9a90122ae8de0bcf19a468d8\n",
      "  Building wheel for tabulate (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/54/f9/95/099544e9f879f719b14cf567fabb5aa7984263df0f025f3eef\n",
      "Successfully built kfp kfp-server-api argo-models tabulate wrapt\n",
      "\u001b[31mkubeflow-tfjob 0.1.3 has requirement kubernetes>=10.0.1, but you'll have kubernetes 9.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mkubeflow-pytorchjob 0.1.3 has requirement kubernetes>=10.0.1, but you'll have kubernetes 9.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mkubeflow-fairing 0.7.1 has requirement kubernetes>=10.0.1, but you'll have kubernetes 9.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mkfserving 0.2.2.1 has requirement kubernetes>=10.0.1, but you'll have kubernetes 9.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: kubernetes, kfp-server-api, argo-models, tabulate, wrapt, Deprecated, kfp\n",
      "  Found existing installation: kubernetes 10.0.1\n",
      "    Uninstalling kubernetes-10.0.1:\n",
      "      Successfully uninstalled kubernetes-10.0.1\n",
      "  Found existing installation: tabulate 0.8.6\n",
      "    Uninstalling tabulate-0.8.6:\n",
      "      Successfully uninstalled tabulate-0.8.6\n",
      "  Found existing installation: kfp 0.1\n",
      "    Uninstalling kfp-0.1:\n",
      "      Successfully uninstalled kfp-0.1\n",
      "Successfully installed Deprecated-1.2.7 argo-models-2.2.1a0 kfp-0.1.29 kfp-server-api-0.1.18.3 kubernetes-9.0.0 tabulate-0.8.3 wrapt-1.12.0\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install https://storage.googleapis.com/ml-pipeline/release/0.1.29/kfp.tar.gz --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run the following command to load Kubeflow Pipelines SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import components\n",
    "from kfp import dsl\n",
    "from kfp.aws import use_aws_secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load reusable sagemaker components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_train_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0ad6c28d32e2e790e6a129b7eb1de8ec59c1d45f/components/aws/sagemaker/train/component.yaml')\n",
    "sagemaker_model_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0ad6c28d32e2e790e6a129b7eb1de8ec59c1d45f/components/aws/sagemaker/model/component.yaml')\n",
    "sagemaker_deploy_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0ad6c28d32e2e790e6a129b7eb1de8ec59c1d45f/components/aws/sagemaker/deploy/component.yaml')\n",
    "sagemaker_batch_transform_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0ad6c28d32e2e790e6a129b7eb1de8ec59c1d45f/components/aws/sagemaker/batch_transform/component.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create pipeline. \n",
    "\n",
    "We will create a training job first. Once training job is done, it will persist trained model to S3. \n",
    "\n",
    "Then a job will be kicked off to create a `Model` manifest in Sagemaker. \n",
    "\n",
    "With this model, batch transformation job can use it to predict on other datasets, prediction service can create an endpoint using it.\n",
    "\n",
    "\n",
    "> Note: remember to use your **role_arn** to successfully run the job.\n",
    "\n",
    "> Note: If you use a different region, please replace `us-west-2` with your region. \n",
    "\n",
    "> Note: ECR Images for k-means algorithm\n",
    "\n",
    "|Region| ECR Image|\n",
    "|------|----------|\n",
    "|us-west-1|632365934929.dkr.ecr.us-west-1.amazonaws.com|\n",
    "|us-west-2|174872318107.dkr.ecr.us-west-2.amazonaws.com|\n",
    "|us-east-1|382416733822.dkr.ecr.us-east-1.amazonaws.com|\n",
    "|us-east-2|404615174143.dkr.ecr.us-east-2.amazonaws.com|\n",
    "|us-gov-west-1|226302683700.dkr.ecr.us-gov-west-1.amazonaws.com|\n",
    "|ap-east-1|286214385809.dkr.ecr.ap-east-1.amazonaws.com|\n",
    "|ap-northeast-1|351501993468.dkr.ecr.ap-northeast-1.amazonaws.com|\n",
    "|ap-northeast-2|835164637446.dkr.ecr.ap-northeast-2.amazonaws.com|\n",
    "|ap-south-1|991648021394.dkr.ecr.ap-south-1.amazonaws.com|\n",
    "|ap-southeast-1|475088953585.dkr.ecr.ap-southeast-1.amazonaws.com|\n",
    "|ap-southeast-2|712309505854.dkr.ecr.ap-southeast-2.amazonaws.com|\n",
    "|ca-central-1|469771592824.dkr.ecr.ca-central-1.amazonaws.com|\n",
    "|eu-central-1|664544806723.dkr.ecr.eu-central-1.amazonaws.com|\n",
    "|eu-north-1|669576153137.dkr.ecr.eu-north-1.amazonaws.com|\n",
    "|eu-west-1|438346466558.dkr.ecr.eu-west-1.amazonaws.com|\n",
    "|eu-west-2|644912444149.dkr.ecr.eu-west-2.amazonaws.com|\n",
    "|eu-west-3|749696950732.dkr.ecr.eu-west-3.amazonaws.com|\n",
    "|me-south-1|249704162688.dkr.ecr.me-south-1.amazonaws.com|\n",
    "|sa-east-1|855470959533.dkr.ecr.sa-east-1.amazonaws.com|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: remember to use your `SAGEMAKER_ROLE_ARN` to successfully run the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your s3 bucket.\n",
    "S3_PIPELINE_PATH='s3://{}/mnist_kmeans_example'.format(S3_BUCKET)\n",
    "\n",
    "# Configure your Sagemaker execution role from the SageMaker Console Notebook Instance Tab\n",
    "SAGEMAKER_ROLE_ARN='arn:aws:iam::173153674984:role/TeamRole'\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='MNIST Classification pipeline',\n",
    "    description='MNIST Classification using KMEANS in SageMaker'\n",
    ")\n",
    "def mnist_classification(region='us-west-2',\n",
    "    image='174872318107.dkr.ecr.us-west-2.amazonaws.com/kmeans:1',\n",
    "    dataset_path=S3_PIPELINE_PATH + '/data',\n",
    "    instance_type='ml.c4.8xlarge',\n",
    "    instance_count='2',\n",
    "    volume_size='50',\n",
    "    model_output_path=S3_PIPELINE_PATH + '/model',\n",
    "    batch_transform_input=S3_PIPELINE_PATH + '/input',\n",
    "    batch_transform_ouput=S3_PIPELINE_PATH + '/output',\n",
    "    role_arn=SAGEMAKER_ROLE_ARN\n",
    "    ):\n",
    "\n",
    "    training = sagemaker_train_op(\n",
    "        region=region,\n",
    "        image=image,\n",
    "        instance_type=instance_type,\n",
    "        instance_count=instance_count,\n",
    "        volume_size=volume_size,\n",
    "        dataset_path=dataset_path,\n",
    "        model_artifact_path=model_output_path,\n",
    "        role=role_arn,\n",
    "    ).apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))\n",
    "\n",
    "    create_model = sagemaker_model_op(\n",
    "        region=region,\n",
    "        image=image,\n",
    "        model_artifact_url=training.outputs['model_artifact_url'],\n",
    "        model_name=training.outputs['job_name'],\n",
    "        role=role_arn\n",
    "    ).apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))\n",
    "\n",
    "    prediction = sagemaker_deploy_op(\n",
    "        region=region,\n",
    "        model_name=create_model.output\n",
    "    ).apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))\n",
    "\n",
    "    batch_transform = sagemaker_batch_transform_op(\n",
    "        region=region,\n",
    "        model_name=create_model.output,\n",
    "        input_location=batch_transform_input,\n",
    "        output_location=batch_transform_ouput\n",
    "    ).apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compile your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(mnist_classification, 'mnist-classification-pipeline.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Deploy your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/bf337dde-8b07-4f58-bce2-49c3b2779e55\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/bdfbdd7d-7f74-452c-9f2c-9eb8a2d523ad\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "aws_experiment = client.create_experiment(name='aws')\n",
    "my_run = client.run_pipeline(aws_experiment.id, 'mnist-classification-pipeline', \n",
    "  'mnist-classification-pipeline.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "_Note:  The above training job may take 5-10 minutes.  Please be patient._\n",
    "\n",
    "In the meantime, open the SageMaker Console to monitor the progress of your training job.\n",
    "\n",
    "![](/images/kubeflow-sagemaker-training-job.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Open the SageMaker console and find your endpoint name. Please check dataset section to get train_set.\n",
    "\n",
    "Once your pipeline is done, you can find sagemaker endpoint name and replace ENDPOINT_NAME value with your newly created endpoint name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find your Endpoint name in AWS Console\n",
    "\n",
    "Open AWS console and enter Sagemaker service, find the endpoint name as the following picture shows.\n",
    "\n",
    "![download-pipeline](images/sm-endpoint.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'distance_to_cluster': 7.251535892486572, 'closest_cluster': 5.0}]}\n"
     ]
    }
   ],
   "source": [
    "import pickle, gzip, numpy, urllib.request, json\n",
    "from urllib.parse import urlparse\n",
    "import json\n",
    "import io\n",
    "import boto3\n",
    "\n",
    "# Replace the endpoint name with yours.\n",
    "ENDPOINT_NAME='Endpoint-20200222203140-PLYF'\n",
    "\n",
    "# Load the dataset\n",
    "urllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", \"mnist.pkl.gz\")\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Simple function to create a csv from our numpy array\n",
    "def np2csv(arr):\n",
    "    csv = io.BytesIO()\n",
    "    numpy.savetxt(csv, arr, delimiter=',', fmt='%g')\n",
    "    return csv.getvalue().decode().rstrip()\n",
    "\n",
    "runtime = boto3.Session(region_name='us-west-2').client('sagemaker-runtime')\n",
    "\n",
    "payload = np2csv(train_set[0][30:31])\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "                                   ContentType='text/csv',\n",
    "                                   Body=payload)\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Go to Sagemaker console and delete `endpoint` and `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
